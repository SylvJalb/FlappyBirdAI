{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import gi\n",
    "gi.require_version(\"Wnck\", \"3.0\")\n",
    "from gi.repository import Wnck\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST OF ALL : Run the game\n",
    "``` bash\n",
    "cd ./FlappyBirdGame\n",
    "python ./flappy.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlappyBirdGame :\n",
    "    def __init__(self, windowName):\n",
    "        scr = Wnck.Screen.get_default()\n",
    "        scr.force_update()\n",
    "        windows = scr.get_windows()\n",
    "        self.flappyBird_window = None\n",
    "        for window in windows:\n",
    "            # if title is \"Flappy Bird\"\n",
    "            if window.get_name() == windowName:\n",
    "                # get the window's geometry\n",
    "                x, y, width, height = window.get_geometry()\n",
    "                self.flappyBird_window = { \"x\": x, \"y\": y, \"width\": width, \"height\": height }\n",
    "                print(\"Game Positions â†“\\n - x :\", x , \"\\n - y :\", y , \"\\n - width :\", width , \"\\n - height :\", height)\n",
    "        if self.flappyBird_window is None:\n",
    "            print(\"Window not found\")\n",
    "        else :\n",
    "            self.flappyBird_click = ( self.flappyBird_window[\"x\"] + self.flappyBird_window[\"width\"]/2, self.flappyBird_window[\"y\"] + self.flappyBird_window[\"height\"] - 30 )\n",
    "            # focus window\n",
    "            self.focus()\n",
    "            # first click\n",
    "            self.get_processed_img()\n",
    "            # init score\n",
    "            self.score = 0.1\n",
    "    \n",
    "    def focus(self):\n",
    "        pyautogui.moveTo(self.flappyBird_click)\n",
    "        pyautogui.click()\n",
    "    \n",
    "    def up(self):\n",
    "        pyautogui.press('space')\n",
    "    \n",
    "    def get_img(self):\n",
    "        # make a screenshot of the window\n",
    "        self.img = pyautogui.screenshot(region=(self.flappyBird_window[\"x\"], self.flappyBird_window[\"y\"], self.flappyBird_window[\"width\"], self.flappyBird_window[\"height\"]))\n",
    "        return self.img\n",
    "    \n",
    "    def get_processed_img(self):\n",
    "        # make a screenshot of the window\n",
    "        img_rgb = self.get_img()\n",
    "        # crop top and bottom of the image\n",
    "        img_rgb = img_rgb.crop((0, img_rgb.height - 512, img_rgb.width, img_rgb.height - 108))\n",
    "        # convert image to numpy array\n",
    "        img_rgb = np.array(img_rgb)\n",
    "        # convert image to grayscale just using green and red channels\n",
    "        img = img_rgb[:,:,1] + img_rgb[:,:,0]\n",
    "        img[img>255] = 255\n",
    "        # threshold image\n",
    "        img = cv2.adaptiveThreshold(img,1,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,21,2)\n",
    "        # resize image\n",
    "        img = cv2.resize(img, (80, 80))\n",
    "        # reshape image to 60x60x1\n",
    "        img = np.reshape(img, (80, 80, 1))\n",
    "        # save processed image\n",
    "        self.processed_img = img\n",
    "        # return the image\n",
    "        return img\n",
    "    \n",
    "    def is_end(self): # True if game over, else False\n",
    "        if self.img.getpixel((100, self.img.height - 305)) == (252, 160, 72):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def startRound(self):\n",
    "        # focus window\n",
    "        self.focus()\n",
    "        # restart the game if it's over\n",
    "        if self.is_end():\n",
    "            sleep(1)\n",
    "            self.up()\n",
    "            sleep(0.1)\n",
    "        # init score\n",
    "        self.score = 0\n",
    "        # start game\n",
    "        self.up()\n",
    "        # first click\n",
    "        self.get_processed_img()\n",
    "    \n",
    "    def get_reward(self):\n",
    "        # if it's the end, the reward is -1\n",
    "        if self.is_end() :\n",
    "            self.score = -1\n",
    "        else :\n",
    "            # init score\n",
    "            self.score = 0.1\n",
    "            # if the bird is between the pipes, the reward is 1\n",
    "            if (np.array(self.img.crop((50, self.img.height - 510, 80, self.img.height - 509))) == (220, 245, 133)).all(axis=2).any() :\n",
    "                self.score = 1\n",
    "        return self.score\n",
    "        \n",
    "\n",
    "    def play(self, action):\n",
    "        if action == 1:\n",
    "            self.up()\n",
    "        # wait 0.1 second\n",
    "        sleep(0.01)\n",
    "        return self.get_processed_img(), self.get_reward(), self.is_end()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a game instance for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = FlappyBirdGame(\"Flappy Bird\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test end of game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(game.is_end())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test screen capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(game.img.crop((50, game.img.height - 510, 80, game.img.height - 509))) == (220, 245, 133)).all(axis=2).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(game.img.crop((50, game.img.height - 510, 80, game.img.height - 509)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(game.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print image\n",
    "\n",
    "plt.imshow(game.processed_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME = 'FlappyBird' # the name of the game being played for log files\n",
    "ACTIONS = 2 # number of valid actions\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "OBSERVE = 20000. # timesteps to observe before training\n",
    "EXPLORE = 40000. # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.0001 # starting value of epsilon\n",
    "REPLAY_MEMORY = 10000 # number of previous transitions to remember\n",
    "BATCH = 32 # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "SAVE_ITERATIONS = 1000 # save model progress every X iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.01, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides = [1, stride, stride, 1], padding = \"SAME\")\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "\n",
    "def createNetwork():\n",
    "    # network weights\n",
    "    W_conv1 = weight_variable([8, 8, 4, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    W_conv2 = weight_variable([4, 4, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    W_conv3 = weight_variable([3, 3, 64, 64])\n",
    "    b_conv3 = bias_variable([64])\n",
    "\n",
    "    W_fc1 = weight_variable([64, 256])\n",
    "    b_fc1 = bias_variable([256])\n",
    "\n",
    "    W_fc2 = weight_variable([256, ACTIONS])\n",
    "    b_fc2 = bias_variable([ACTIONS])\n",
    "\n",
    "    # input layer\n",
    "    s = tf.placeholder(\"float\", [None, 80, 80, 4])\n",
    "\n",
    "    # hidden layers\n",
    "    h_conv1 = tf.nn.relu(conv2d(s, W_conv1, 4) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3, 1) + b_conv3)\n",
    "    h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 64])\n",
    "\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # readout layer\n",
    "    readout = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "    return s, readout, h_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNetwork(s, readout, h_fc1, sess):\n",
    "    # define the cost function\n",
    "    a = tf.placeholder(\"float\", [None, ACTIONS])\n",
    "    y = tf.placeholder(\"float\", [None])\n",
    "    readout_action = tf.reduce_sum(tf.multiply(readout, a), reduction_indices=1)\n",
    "    cost = tf.reduce_mean(tf.square(y - readout_action))\n",
    "    train_step = tf.train.AdamOptimizer(1e-6).minimize(cost)\n",
    "\n",
    "    # open up a game state to communicate with emulator\n",
    "    game = FlappyBirdGame(\"Flappy Bird\")\n",
    "\n",
    "    # store the previous observations in replay memory\n",
    "    D = deque()\n",
    "\n",
    "    # printing\n",
    "    # a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "    # h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "    # get the first state by doing nothing and preprocess the image to 80x80x4\n",
    "    game.startRound()\n",
    "    image, reward, terminal = game.play(0) # do nothing\n",
    "    images_last_t = np.squeeze(np.flip(np.stack((image, image, image, image), axis=2), 0), axis=3)\n",
    "\n",
    "    # saving and loading networks\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    checkpoint = tf.train.get_checkpoint_state(\"saved_networks\")\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        print(\"Successfully loaded:\", checkpoint.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Could not find old network weights\")\n",
    "\n",
    "    # start training\n",
    "    epsilon = INITIAL_EPSILON\n",
    "    t = 0\n",
    "    \n",
    "    while True:\n",
    "        print(\"t = \", t)\n",
    "        # run model and get the action\n",
    "        readout_t = readout.eval(feed_dict={s : [images_last_t]})[0]\n",
    "        action_t = np.zeros([ACTIONS])\n",
    "        action_t_index = 0\n",
    "\n",
    "        # sometimes do a random action (exploration)\n",
    "        if random.random() <= epsilon:\n",
    "            print(\"Do a random action !\")\n",
    "            action_t_index = random.randrange(ACTIONS)\n",
    "            action_t[action_t_index] = 1\n",
    "        else :\n",
    "            action_t_index = np.argmax(readout_t)\n",
    "            action_t[action_t_index] = 1\n",
    "        \n",
    "        \n",
    "\n",
    "        # scale down epsilon\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "        # run the selected action and observe next state and reward\n",
    "        image_t, reward_t, terminal = game.play(action_t_index)\n",
    "        images_t = np.append(image_t, images_last_t[:, :, :3], axis=2)\n",
    "\n",
    "        # store the transition in D\n",
    "        D.append((images_last_t, action_t, reward_t, images_t, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        # only train if done observing\n",
    "        if t > OBSERVE:\n",
    "            # sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "\n",
    "            # get the batch variables\n",
    "            images_last_t_batch = [d[0] for d in minibatch]\n",
    "            action_batch = [d[1] for d in minibatch]\n",
    "            reward_batch = [d[2] for d in minibatch]\n",
    "            images_t_batch = [d[3] for d in minibatch]\n",
    "\n",
    "            y_batch = []\n",
    "            readout_batch = readout.eval(feed_dict = {s : images_t_batch})\n",
    "            for i in range(0, len(minibatch)):\n",
    "                terminal_i = minibatch[i][4]\n",
    "                # if terminal_i, only equals reward\n",
    "                if terminal_i:\n",
    "                    y_batch.append(reward_batch[i])\n",
    "                else:\n",
    "                    y_batch.append(reward_batch[i] + GAMMA * np.max(readout_batch[i]))\n",
    "\n",
    "            # perform gradient step\n",
    "            train_step.run(feed_dict = {\n",
    "                y : y_batch,\n",
    "                a : action_batch,\n",
    "                s : images_last_t_batch}\n",
    "            )\n",
    "\n",
    "        # update the old values\n",
    "        images_last_t = images_t\n",
    "        t += 1\n",
    "\n",
    "        # save progress every SAVE_ITERATIONS iterations   \n",
    "        if t % SAVE_ITERATIONS == 0:\n",
    "            saver.save(sess, 'saved_networks/' + GAME + '-dqn', global_step = t)\n",
    "\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state, \\\n",
    "            \"/ EPSILON\", epsilon, \"/ ACTION\", action_t_index, \"/ REWARD\", reward_t, \\\n",
    "            \"/ Q_MAX %e\" % np.max(readout_t))\n",
    "        \n",
    "        if terminal:\n",
    "            game.startRound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTrain():\n",
    "    sess = tf.InteractiveSession()\n",
    "    s, readout, h_fc1 = createNetwork()\n",
    "    trainNetwork(s, readout, h_fc1, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests and verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyautogui.confirm('Start AI?', buttons=['Go!'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('FlappyBirdIA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a695e129c08a1f9c49892acab485f71b07168fb63b09b205de0644704f566243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
